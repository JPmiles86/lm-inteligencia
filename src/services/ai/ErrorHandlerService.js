// Error Handler Service - Comprehensive error mapping and recovery strategies
// Handles provider-specific errors, retry logic, and recovery actions

export class ErrorHandlerService {
  constructor() {
    this.errorStats = new Map();
    this.circuitBreakers = new Map();
    this.retryStrategies = new Map();
    
    this.initializeRetryStrategies();
    this.initializeCircuitBreakers();
  }

  // ================================
  // ERROR CLASSIFICATION
  // ================================

  classifyError(error, provider, context = {}) {
    const classification = {
      type: 'unknown',
      severity: 'medium',
      retryable: false,
      retryStrategy: null,
      circuitBreakerAction: null,
      userMessage: 'An error occurred while processing your request.',
      technicalMessage: error.message,
      provider,
      context,
      timestamp: new Date().toISOString(),
      errorCode: this.extractErrorCode(error),
      httpStatus: this.extractHttpStatus(error)
    };

    // Classify by error message and status
    this.classifyByMessage(error, classification);
    this.classifyByStatus(error, classification);
    this.classifyByProvider(error, provider, classification);
    
    // Apply provider-specific overrides
    this.applyProviderSpecificRules(classification, provider);
    
    // Log error for analysis
    this.logError(classification);
    
    return classification;
  }

  classifyByMessage(error, classification) {
    const message = error.message.toLowerCase();
    
    // Rate limiting errors
    if (message.includes('rate limit') || message.includes('too many requests')) {
      classification.type = 'rate_limit';
      classification.severity = 'low';
      classification.retryable = true;
      classification.retryStrategy = 'exponential_backoff';
      classification.userMessage = 'Service is temporarily busy. Please try again in a moment.';
      return;
    }
    
    // Authentication errors
    if (message.includes('authentication') || message.includes('invalid api key') || message.includes('unauthorized')) {
      classification.type = 'authentication';
      classification.severity = 'high';
      classification.retryable = false;
      classification.userMessage = 'Authentication error. Please check your API configuration.';
      classification.circuitBreakerAction = 'open';
      return;
    }
    
    // Quota/billing errors
    if (message.includes('quota') || message.includes('insufficient') || message.includes('billing')) {
      classification.type = 'quota_exceeded';
      classification.severity = 'high';
      classification.retryable = false;
      classification.userMessage = 'Service quota exceeded. Please check your account limits.';
      classification.circuitBreakerAction = 'open';
      return;
    }
    
    // Content filtering
    if (message.includes('content') && (message.includes('blocked') || message.includes('filtered') || message.includes('violated'))) {\n      classification.type = 'content_filtered';\n      classification.severity = 'medium';\n      classification.retryable = false;\n      classification.userMessage = 'Content was blocked by safety filters. Please modify your request.';\n      return;\n    }\n    \n    // Timeout errors\n    if (message.includes('timeout') || message.includes('timed out')) {\n      classification.type = 'timeout';\n      classification.severity = 'medium';\n      classification.retryable = true;\n      classification.retryStrategy = 'linear_backoff';\n      classification.userMessage = 'Request timed out. Please try again.';\n      return;\n    }\n    \n    // Server errors\n    if (message.includes('server error') || message.includes('internal error') || message.includes('service unavailable')) {\n      classification.type = 'server_error';\n      classification.severity = 'medium';\n      classification.retryable = true;\n      classification.retryStrategy = 'exponential_backoff';\n      classification.userMessage = 'Server error occurred. Please try again shortly.';\n      return;\n    }\n    \n    // Network errors\n    if (message.includes('network') || message.includes('connection') || message.includes('econnreset')) {\n      classification.type = 'network_error';\n      classification.severity = 'medium';\n      classification.retryable = true;\n      classification.retryStrategy = 'exponential_backoff';\n      classification.userMessage = 'Network error occurred. Please check your connection.';\n      return;\n    }\n    \n    // Model errors\n    if (message.includes('model') && (message.includes('not found') || message.includes('not supported') || message.includes('unavailable'))) {\n      classification.type = 'model_error';\n      classification.severity = 'medium';\n      classification.retryable = false;\n      classification.userMessage = 'The requested AI model is not available. Please try a different model.';\n      return;\n    }\n    \n    // Token/context length errors\n    if (message.includes('token') && (message.includes('limit') || message.includes('exceeded') || message.includes('too long'))) {\n      classification.type = 'token_limit';\n      classification.severity = 'medium';\n      classification.retryable = false;\n      classification.userMessage = 'Request is too long. Please reduce the content length.';\n      return;\n    }\n    \n    // Validation errors\n    if (message.includes('invalid') || message.includes('malformed') || message.includes('bad request')) {\n      classification.type = 'validation_error';\n      classification.severity = 'low';\n      classification.retryable = false;\n      classification.userMessage = 'Invalid request format. Please check your input.';\n      return;\n    }\n  }\n\n  classifyByStatus(error, classification) {\n    const status = this.extractHttpStatus(error);\n    if (!status) return;\n    \n    switch (status) {\n      case 400:\n        classification.type = classification.type === 'unknown' ? 'validation_error' : classification.type;\n        classification.severity = 'low';\n        break;\n      case 401:\n        classification.type = 'authentication';\n        classification.severity = 'high';\n        classification.circuitBreakerAction = 'open';\n        break;\n      case 403:\n        classification.type = 'authorization';\n        classification.severity = 'high';\n        break;\n      case 404:\n        classification.type = 'not_found';\n        classification.severity = 'medium';\n        break;\n      case 429:\n        classification.type = 'rate_limit';\n        classification.severity = 'low';\n        classification.retryable = true;\n        classification.retryStrategy = 'exponential_backoff';\n        break;\n      case 500:\n      case 502:\n      case 503:\n      case 504:\n        classification.type = 'server_error';\n        classification.severity = 'medium';\n        classification.retryable = true;\n        classification.retryStrategy = 'exponential_backoff';\n        break;\n    }\n  }\n\n  classifyByProvider(error, provider, classification) {\n    switch (provider) {\n      case 'openai':\n        this.classifyOpenAIError(error, classification);\n        break;\n      case 'anthropic':\n        this.classifyAnthropicError(error, classification);\n        break;\n      case 'google':\n        this.classifyGoogleError(error, classification);\n        break;\n      case 'perplexity':\n        this.classifyPerplexityError(error, classification);\n        break;\n    }\n  }\n\n  classifyOpenAIError(error, classification) {\n    // OpenAI-specific error handling\n    if (error.type) {\n      switch (error.type) {\n        case 'insufficient_quota':\n          classification.type = 'quota_exceeded';\n          classification.userMessage = 'OpenAI quota exceeded. Please check your billing.';\n          break;\n        case 'model_not_found':\n          classification.type = 'model_error';\n          classification.userMessage = 'The requested OpenAI model is not available.';\n          break;\n        case 'rate_limit_error':\n          classification.type = 'rate_limit';\n          classification.retryable = true;\n          classification.retryStrategy = 'exponential_backoff';\n          break;\n        case 'server_error':\n          classification.type = 'server_error';\n          classification.retryable = true;\n          break;\n      }\n    }\n    \n    // Handle incomplete responses\n    if (error.status === 'incomplete') {\n      const reason = error.incomplete_details?.reason;\n      if (reason === 'max_output_tokens') {\n        classification.type = 'token_limit';\n        classification.userMessage = 'Response was truncated. Please request a shorter response.';\n      } else if (reason === 'content_filter') {\n        classification.type = 'content_filtered';\n        classification.userMessage = 'Content was blocked by safety filters.';\n      }\n    }\n  }\n\n  classifyAnthropicError(error, classification) {\n    // Anthropic-specific error handling\n    const message = error.message.toLowerCase();\n    \n    if (message.includes('overloaded')) {\n      classification.type = 'server_overloaded';\n      classification.retryable = true;\n      classification.retryStrategy = 'linear_backoff';\n      classification.userMessage = 'Anthropic servers are overloaded. Please try again shortly.';\n    }\n    \n    if (message.includes('context length')) {\n      classification.type = 'context_length';\n      classification.userMessage = 'Context is too long for this Anthropic model. Please reduce input length.';\n    }\n  }\n\n  classifyGoogleError(error, classification) {\n    // Google-specific error handling\n    const message = error.message.toLowerCase();\n    \n    if (message.includes('blocked')) {\n      classification.type = 'content_blocked';\n      classification.userMessage = 'Content was blocked by Google\\'s safety systems.';\n    }\n    \n    if (message.includes('quota')) {\n      classification.type = 'quota_exceeded';\n      classification.userMessage = 'Google AI quota exceeded. Please check your usage limits.';\n    }\n    \n    if (message.includes('region')) {\n      classification.type = 'region_unavailable';\n      classification.userMessage = 'Google AI is not available in your region.';\n    }\n  }\n\n  classifyPerplexityError(error, classification) {\n    // Perplexity-specific error handling\n    const message = error.message.toLowerCase();\n    \n    if (message.includes('domain filter')) {\n      classification.type = 'domain_filter_error';\n      classification.userMessage = 'Domain filter configuration is invalid. Maximum 10 domains allowed.';\n    }\n    \n    if (message.includes('date format')) {\n      classification.type = 'date_format_error';\n      classification.userMessage = 'Date filter format is invalid. Use MM/DD/YYYY format.';\n    }\n  }\n\n  applyProviderSpecificRules(classification, provider) {\n    // Apply provider-specific retry and circuit breaker rules\n    const rules = this.getProviderRules(provider);\n    \n    if (rules.disableRetry?.includes(classification.type)) {\n      classification.retryable = false;\n      classification.retryStrategy = null;\n    }\n    \n    if (rules.forceCircuitBreaker?.includes(classification.type)) {\n      classification.circuitBreakerAction = 'open';\n    }\n    \n    if (rules.customMessages?.[classification.type]) {\n      classification.userMessage = rules.customMessages[classification.type];\n    }\n  }\n\n  getProviderRules(provider) {\n    const rules = {\n      openai: {\n        disableRetry: ['insufficient_quota', 'model_not_found'],\n        forceCircuitBreaker: ['authentication', 'insufficient_quota'],\n        customMessages: {\n          rate_limit: 'OpenAI rate limit reached. Please wait before trying again.'\n        }\n      },\n      anthropic: {\n        disableRetry: ['context_length'],\n        forceCircuitBreaker: ['authentication', 'quota_exceeded'],\n        customMessages: {\n          server_overloaded: 'Anthropic is experiencing high demand. Please try again in a few minutes.'\n        }\n      },\n      google: {\n        disableRetry: ['region_unavailable'],\n        forceCircuitBreaker: ['authentication', 'quota_exceeded'],\n        customMessages: {\n          content_blocked: 'Content violated Google\\'s usage policies. Please modify your request.'\n        }\n      },\n      perplexity: {\n        disableRetry: ['domain_filter_error', 'date_format_error'],\n        customMessages: {\n          domain_filter_error: 'Invalid search domain configuration. Please check your domain filters.'\n        }\n      }\n    };\n    \n    return rules[provider] || {};\n  }\n\n  // ================================\n  // RETRY STRATEGIES\n  // ================================\n\n  initializeRetryStrategies() {\n    this.retryStrategies.set('exponential_backoff', {\n      maxRetries: 3,\n      baseDelay: 1000,\n      maxDelay: 30000,\n      backoffFactor: 2,\n      jitter: true\n    });\n    \n    this.retryStrategies.set('linear_backoff', {\n      maxRetries: 3,\n      baseDelay: 2000,\n      maxDelay: 10000,\n      backoffFactor: 1,\n      jitter: true\n    });\n    \n    this.retryStrategies.set('immediate_retry', {\n      maxRetries: 1,\n      baseDelay: 0,\n      maxDelay: 0,\n      backoffFactor: 1,\n      jitter: false\n    });\n  }\n\n  async executeWithRetry(operation, errorClassification, context = {}) {\n    if (!errorClassification.retryable || !errorClassification.retryStrategy) {\n      return await operation();\n    }\n    \n    const strategy = this.retryStrategies.get(errorClassification.retryStrategy);\n    if (!strategy) {\n      return await operation();\n    }\n    \n    let lastError;\n    \n    for (let attempt = 1; attempt <= strategy.maxRetries + 1; attempt++) {\n      try {\n        return await operation();\n      } catch (error) {\n        lastError = error;\n        \n        if (attempt > strategy.maxRetries) {\n          break;\n        }\n        \n        // Calculate delay\n        let delay = strategy.baseDelay * Math.pow(strategy.backoffFactor, attempt - 1);\n        delay = Math.min(delay, strategy.maxDelay);\n        \n        // Add jitter\n        if (strategy.jitter) {\n          delay += Math.random() * 1000;\n        }\n        \n        console.warn(`Retry attempt ${attempt}/${strategy.maxRetries} after ${delay}ms for ${errorClassification.type}`);\n        \n        if (delay > 0) {\n          await this.delay(delay);\n        }\n      }\n    }\n    \n    throw lastError;\n  }\n\n  delay(ms) {\n    return new Promise(resolve => setTimeout(resolve, ms));\n  }\n\n  // ================================\n  // CIRCUIT BREAKER\n  // ================================\n\n  initializeCircuitBreakers() {\n    // Initialize circuit breakers for each provider\n    const providers = ['openai', 'anthropic', 'google', 'perplexity'];\n    \n    providers.forEach(provider => {\n      this.circuitBreakers.set(provider, {\n        state: 'closed', // closed, open, half-open\n        failureCount: 0,\n        lastFailureTime: null,\n        successCount: 0,\n        threshold: 5, // failures to open\n        timeout: 60000, // 1 minute timeout\n        halfOpenMaxCalls: 3\n      });\n    });\n  }\n\n  checkCircuitBreaker(provider) {\n    const breaker = this.circuitBreakers.get(provider);\n    if (!breaker) return true; // Allow if no breaker configured\n    \n    const now = Date.now();\n    \n    switch (breaker.state) {\n      case 'closed':\n        return true;\n        \n      case 'open':\n        if (now - breaker.lastFailureTime >= breaker.timeout) {\n          breaker.state = 'half-open';\n          breaker.successCount = 0;\n          return true;\n        }\n        return false;\n        \n      case 'half-open':\n        return breaker.successCount < breaker.halfOpenMaxCalls;\n        \n      default:\n        return true;\n    }\n  }\n\n  recordSuccess(provider) {\n    const breaker = this.circuitBreakers.get(provider);\n    if (!breaker) return;\n    \n    if (breaker.state === 'half-open') {\n      breaker.successCount++;\n      if (breaker.successCount >= breaker.halfOpenMaxCalls) {\n        breaker.state = 'closed';\n        breaker.failureCount = 0;\n      }\n    } else if (breaker.state === 'closed') {\n      breaker.failureCount = 0;\n    }\n  }\n\n  recordFailure(provider, errorClassification) {\n    const breaker = this.circuitBreakers.get(provider);\n    if (!breaker) return;\n    \n    breaker.failureCount++;\n    breaker.lastFailureTime = Date.now();\n    \n    if (errorClassification.circuitBreakerAction === 'open' || \n        breaker.failureCount >= breaker.threshold) {\n      breaker.state = 'open';\n      console.warn(`Circuit breaker opened for provider ${provider}`);\n    }\n  }\n\n  getCircuitBreakerState(provider) {\n    const breaker = this.circuitBreakers.get(provider);\n    return breaker ? breaker.state : 'unknown';\n  }\n\n  // ================================\n  // ERROR RECOVERY\n  // ================================\n\n  async attemptRecovery(errorClassification, context = {}) {\n    const recoveryActions = {\n      token_limit: () => this.suggestTokenReduction(context),\n      context_length: () => this.suggestContextReduction(context),\n      model_error: () => this.suggestModelAlternatives(context),\n      quota_exceeded: () => this.suggestQuotaManagement(context),\n      content_filtered: () => this.suggestContentModification(context),\n      rate_limit: () => this.suggestRateManagement(context)\n    };\n    \n    const action = recoveryActions[errorClassification.type];\n    if (action) {\n      return await action();\n    }\n    \n    return null;\n  }\n\n  suggestTokenReduction(context) {\n    return {\n      action: 'reduce_tokens',\n      suggestions: [\n        'Reduce the input text length',\n        'Use a model with higher token limits',\n        'Split the request into smaller parts',\n        'Use summarization before processing'\n      ],\n      maxTokensRecommended: Math.floor((context.currentTokens || 4000) * 0.8)\n    };\n  }\n\n  suggestContextReduction(context) {\n    return {\n      action: 'reduce_context',\n      suggestions: [\n        'Remove less relevant context information',\n        'Use shorter conversation history',\n        'Summarize previous context',\n        'Use a model with larger context window'\n      ]\n    };\n  }\n\n  suggestModelAlternatives(context) {\n    const alternatives = {\n      openai: ['gpt-4.1', 'gpt-5-mini'],\n      anthropic: ['claude-sonnet-4', 'claude-haiku-4'],\n      google: ['gemini-2.5-flash', 'gemini-2.5-flash-lite'],\n      perplexity: ['sonar', 'sonar-pro']\n    };\n    \n    return {\n      action: 'change_model',\n      alternatives: alternatives[context.provider] || [],\n      suggestion: 'Try using an alternative model'\n    };\n  }\n\n  suggestQuotaManagement(context) {\n    return {\n      action: 'manage_quota',\n      suggestions: [\n        'Check your account billing and limits',\n        'Upgrade your subscription plan',\n        'Wait for quota to reset',\n        'Use a different provider as fallback'\n      ]\n    };\n  }\n\n  suggestContentModification(context) {\n    return {\n      action: 'modify_content',\n      suggestions: [\n        'Review and modify sensitive content',\n        'Use more neutral language',\n        'Remove potentially problematic terms',\n        'Try rephrasing the request'\n      ]\n    };\n  }\n\n  suggestRateManagement(context) {\n    return {\n      action: 'manage_rate_limit',\n      suggestions: [\n        'Implement request queuing',\n        'Add delays between requests',\n        'Use multiple API keys',\n        'Switch to a different provider temporarily'\n      ],\n      retryAfter: this.extractRetryAfter(context.error) || 60\n    };\n  }\n\n  // ================================\n  // UTILITY METHODS\n  // ================================\n\n  extractErrorCode(error) {\n    return error.code || error.error_code || error.type || null;\n  }\n\n  extractHttpStatus(error) {\n    return error.status || error.statusCode || error.response?.status || null;\n  }\n\n  extractRetryAfter(error) {\n    const retryAfter = error.headers?.['retry-after'] || error.retryAfter;\n    return retryAfter ? parseInt(retryAfter) : null;\n  }\n\n  logError(classification) {\n    // Track error statistics\n    const key = `${classification.provider}_${classification.type}`;\n    const current = this.errorStats.get(key) || { count: 0, lastSeen: null };\n    \n    this.errorStats.set(key, {\n      count: current.count + 1,\n      lastSeen: classification.timestamp,\n      classification\n    });\n    \n    // Log to console (in production, send to logging service)\n    console.error('AI Error Classification:', {\n      provider: classification.provider,\n      type: classification.type,\n      severity: classification.severity,\n      retryable: classification.retryable,\n      message: classification.technicalMessage\n    });\n  }\n\n  getErrorStatistics() {\n    const stats = {};\n    \n    this.errorStats.forEach((value, key) => {\n      stats[key] = {\n        count: value.count,\n        lastSeen: value.lastSeen,\n        type: value.classification.type,\n        severity: value.classification.severity\n      };\n    });\n    \n    return stats;\n  }\n\n  clearErrorStatistics() {\n    this.errorStats.clear();\n  }\n\n  // ================================\n  // ERROR REPORTING\n  // ================================\n\n  generateErrorReport(timeframe = '24h') {\n    const now = new Date();\n    const cutoff = new Date(now.getTime() - this.parseTimeframe(timeframe));\n    \n    const report = {\n      timeframe,\n      generatedAt: now.toISOString(),\n      totalErrors: 0,\n      errorsByType: {},\n      errorsByProvider: {},\n      criticalErrors: [],\n      circuitBreakerStates: {}\n    };\n    \n    // Analyze error statistics\n    this.errorStats.forEach((value, key) => {\n      const lastSeen = new Date(value.lastSeen);\n      if (lastSeen < cutoff) return;\n      \n      report.totalErrors += value.count;\n      \n      const type = value.classification.type;\n      const provider = value.classification.provider;\n      \n      report.errorsByType[type] = (report.errorsByType[type] || 0) + value.count;\n      report.errorsByProvider[provider] = (report.errorsByProvider[provider] || 0) + value.count;\n      \n      if (value.classification.severity === 'high') {\n        report.criticalErrors.push({\n          key,\n          count: value.count,\n          lastSeen: value.lastSeen,\n          classification: value.classification\n        });\n      }\n    });\n    \n    // Add circuit breaker states\n    this.circuitBreakers.forEach((breaker, provider) => {\n      report.circuitBreakerStates[provider] = {\n        state: breaker.state,\n        failureCount: breaker.failureCount,\n        lastFailureTime: breaker.lastFailureTime\n      };\n    });\n    \n    return report;\n  }\n\n  parseTimeframe(timeframe) {\n    const match = timeframe.match(/(\\d+)([hd])/); \n    if (!match) return 24 * 60 * 60 * 1000; // Default 24 hours\n    \n    const value = parseInt(match[1]);\n    const unit = match[2];\n    \n    switch (unit) {\n      case 'h': return value * 60 * 60 * 1000;\n      case 'd': return value * 24 * 60 * 60 * 1000;\n      default: return 24 * 60 * 60 * 1000;\n    }\n  }\n}